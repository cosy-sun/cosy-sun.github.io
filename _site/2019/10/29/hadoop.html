<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Hadoop | cosy-sun</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Hadoop" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="hdfs:分布式文件系统" />
<meta property="og:description" content="hdfs:分布式文件系统" />
<link rel="canonical" href="/2019/10/29/hadoop.html" />
<meta property="og:url" content="/2019/10/29/hadoop.html" />
<meta property="og:site_name" content="cosy-sun" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-10-29T00:00:00+08:00" />
<script type="application/ld+json">
{"url":"/2019/10/29/hadoop.html","description":"hdfs:分布式文件系统","headline":"Hadoop","dateModified":"2019-10-29T00:00:00+08:00","datePublished":"2019-10-29T00:00:00+08:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/10/29/hadoop.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css">
  <link rel="icon" type= "image/x-icon" href="../image/szh.ico"><link type="application/atom+xml" rel="alternate" href="/feed.xml" title="cosy-sun" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">cosy-sun</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Hadoop</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2019-10-29T00:00:00+08:00" itemprop="datePublished">Oct 29, 2019
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul>
  <li>
    <p>hdfs:分布式文件系统</p>

    <ul>
      <li>大数据文件,</li>
      <li>文件分块存储, 多机读取效率高与单机读取</li>
      <li>流式数据访问:不支持动态改变文件, 一次写入就不做变化, 要变化只能在文件末尾改变</li>
      <li>硬件故障, 将一个文件块副本分配到不同的机器上,</li>
      <li>
        <p>master/slave</p>

        <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  一个HDFS集群是有一个Namenode和一定数目的Datanode组成。Namenode是一个中心服务器，负责管理文件系统的namespace和客户端对文件的访问。Datanode在集群中一般是一个节点一个，负责管理节点上它们附带的存储。在内部，一个文件其实分成一个或多个block，这些block存储在Datanode集合里。Namenode执行文件系统的namespace操作，例如打开、关闭、重命名文件和目录，同时决定block到具体Datanode节点的映射。Datanode在Namenode的指挥下进行block的创建、删除和复制。Namenode和Datanode都是设计成可以跑在普通的廉价的运行linux的机器上
</code></pre></div>        </div>
      </li>
      <li>将一个文件分块,通常是64M</li>
      <li>namenode:如果主namenode失效,启动备份namenode, 保存整个文件系统的目录信息, 文件信息和分块信息,</li>
    </ul>
  </li>
  <li>
    <p>hadoop目录说明</p>

    <ul>
      <li>bin, hadoop最基本的管理脚本和使用脚本所在目录</li>
      <li>etc, 配置文件所在目录(core-site.xml, hdfs-site.xml, mappred-site.xml)</li>
      <li>include,</li>
      <li>lib, 对外提供的动态编程库</li>
      <li>libexec, shell配置信息</li>
      <li>sbin,</li>
      <li>share, 各个模块编译之后的jar包所在目录</li>
    </ul>
  </li>
  <li>
    <p>hadoop-shell</p>

    <ul>
      <li>创建文件夹
        <ul>
          <li>hadoop fs -mkdir /… 创建文件夹</li>
          <li>hadoop fs -mkdirhdfs://hadoop1:9000/…</li>
        </ul>
      </li>
      <li>上传文件
        <ul>
          <li>hadoop fs -put… …</li>
          <li>hadoop fs -copyFromLocal … …</li>
        </ul>
      </li>
      <li>
        <p>显示目录结构</p>

        <ul>
          <li>hadoop fs -ls -R /</li>
        </ul>
      </li>
      <li>
        <p>复制文件到本地文件系统</p>

        <ul>
          <li>hadoop fs -get … …</li>
        </ul>
      </li>
      <li>
        <p>显示目录中所有文件的大小</p>

        <ul>
          <li>hadoop fs  -du …</li>
        </ul>
      </li>
      <li>
        <p>统计文件夹数量</p>

        <ul>
          <li>hadoop fs -count /…</li>
        </ul>
      </li>
      <li>
        <p>-mv 移动</p>
      </li>
      <li>
        <p>-cp 复制</p>
      </li>
      <li>-moveFromLocal 从本地移动</li>
      <li>
        <p>-getmerge 合并到本地</p>
      </li>
      <li>-cat 查看文件内容</li>
      <li>-text 查看文件内容</li>
      <li>-touchz 创建空白文件</li>
      <li>-stat 查看统计信息</li>
      <li>-tail 查看文件尾部内容</li>
      <li>-chmod 修改文件权限</li>
      <li>-chown 修改属主</li>
      <li>-rm 删除</li>
      <li>-rmr 递归删文件</li>
    </ul>
  </li>
  <li>
    <p>java-api(hadoop)</p>

    <ul>
      <li>hdfs文件到本地文件, filesystem, open , in, out , ioutils</li>
      <li>上传文件, filesystem.create</li>
      <li>删除文件, filesystem.delete</li>
      <li>创建文件, filesystem.mkdirs</li>
    </ul>
  </li>
  <li>
    <p>hadoop分布式系统部署</p>

    <ul>
      <li>主备namenode, 一个处于active状态, 一个处于standby状态,仅仅同步active节点的状态,</li>
      <li>配置hosts文件</li>
      <li>配置ssh免密登录</li>
      <li>关闭防火墙, systemctl disable iptables.server</li>
      <li>上传服务器</li>
      <li>修改hadoop-env.sh配置文件,添加java-home配置</li>
      <li>修改core-site.xml,</li>
      <li>修改hdfs-site.xml,</li>
      <li>修改mapred-site.xml, 指定mapreduce运行在yarn环境</li>
      <li>修改yarn-site.xml,</li>
    </ul>
  </li>
  <li>
    <p>mapreduce</p>

    <p>将作业拆分成不同的map, 然后分配到不同节点取执行, map重在处理输入数据, reduce主要是把前面若干个map的结果汇总到一起输出,</p>
    <ul>
      <li>wordcount</li>
      <li>mapreduce分区,可以将map中的key进行区分, 进入到不同的reduce中,</li>
    </ul>
  </li>
  <li>yarn任务过程分析
    <ul>
      <li>yarn resourcesmanager: 用来管理协调分布式集群的资源</li>
      <li>yarn nodemanager: 用来启动和监控计算机资源单位container的利用情况</li>
      <li>
        <p>流程</p>

        <ul>
          <li></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>hive:hadoop的数据仓库工具</p>
  </li>
  <li>
    <p>pig:基于hadoop的大规模数据分析工具</p>
  </li>
  <li>
    <p>hbase:分布式存储系统,高可靠性,高性能,面向列,可伸缩</p>
  </li>
  <li>zookeeper:</li>
</ul>

  </div><a class="u-url" href="/2019/10/29/hadoop.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <!--<h2 class="footer-heading">cosy-sun</h2>-->

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">cosy-sun</li><li><a class="u-email" href="mailto:737387998@qq.com">737387998@qq.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/cosy-sun"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">cosy-sun</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>孙振华的博客</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
